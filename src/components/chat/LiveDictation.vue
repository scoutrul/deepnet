<template>
  <div class="live-dictation bg-white rounded-xl border border-slate-200 shadow-sm">
    <div class="px-6 py-4 border-b border-slate-200 flex items-center justify-between">
      <h2 class="text-lg font-semibold text-gray-800">–ñ–∏–≤–∞—è –¥–∏–∫—Ç–æ–≤–∫–∞</h2>
      <div class="flex items-center gap-3">
        <div class="text-xs text-slate-500 hidden sm:block">–†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è ‚Ä¢ DeepGram</div>
        <button
          @click="toggleDictation"
          :class="[
            'px-3 py-1.5 text-xs sm:text-sm font-medium rounded-lg transition-all duration-200 flex items-center gap-2',
            isRecording
              ? 'text-white bg-red-500 hover:bg-red-600 shadow'
              : (isInitializing)
                ? 'text-gray-500 bg-gray-100 cursor-not-allowed'
                : 'text-green-600 bg-green-50 hover:bg-green-100 border border-green-200'
          ]"
          :disabled="isInitializing"
        >
          <span :class="['w-2.5 h-2.5 rounded-full', isRecording ? 'bg-white animate-pulse' : isInitializing ? 'bg-gray-400 animate-spin' : 'bg-green-500']"></span>
          <span v-if="isInitializing">–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è‚Ä¶</span>
          <span v-else-if="isRecording">–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å</span>
          <span v-else>–ù–∞—á–∞—Ç—å</span>
        </button>
      </div>
    </div>
    <div class="px-6 py-6">
      <div :class="['overflow-y-auto rounded-lg border border-slate-200 bg-white', panelHeight]" ref="scrollArea">
        <div class="prose prose-sm max-w-none p-4 whitespace-pre-wrap">
          <p class="leading-7 text-slate-800">
            <span v-for="(chunk, idx) in completedChunks" :key="'c'+idx">
              <br v-if="chunk === '\n'" />
              <span v-else class="mr-1 text-slate-800">{{ chunk }}</span>
            </span>
            <span v-if="currentPartial" class="text-slate-500">
              {{ currentPartial }}
              <span class="ml-1 inline-block w-2 h-5 align-baseline bg-slate-400 animate-pulse"></span>
            </span>
            <span v-else-if="!completedChunks.length" class="text-slate-400">–ì–æ–≤–æ—Ä–∏—Ç–µ ‚Äî —Ç–µ–∫—Å—Ç –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å‚Ä¶</span>
          </p>
        </div>
      </div>
      <div class="mt-3 text-xs text-slate-500 flex items-center gap-3">
        <span :class="['w-2 h-2 rounded-full', isRecording ? 'bg-green-500' : 'bg-slate-300']"></span>
        <span>
          {{ isRecording ? '–î–∏–∫—Ç–æ–≤–∫–∞ –∞–∫—Ç–∏–≤–Ω–∞' : '–î–∏–∫—Ç–æ–≤–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞' }}
          <span v-if="!hasDeepGramKey" class="ml-2 text-amber-600">(DeepGram –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)</span>
          <span v-if="useVAD && vadState" class="ml-2">
            ‚Ä¢ VAD: {{ vadState.isSpeaking ? 'üé§ —Ä–µ—á—å' : 'üîá —Ç–∏—à–∏–Ω–∞' }} 
            ({{ Math.round(vadState.currentVolume * 1000) }})
            <span v-if="vadState.hadSufficientPause && !vadState.isSpeaking" class="text-blue-600">‚úì –ø–∞—É–∑–∞</span>
            <span v-if="vadState.shouldFlushBatch" class="text-orange-600 font-medium">‚ö° –æ—Ç–ø—Ä–∞–≤–∫–∞</span>
          </span>
        </span>
      </div>
      <div v-if="errorMessage" class="mt-2 text-xs text-red-600 bg-red-50 px-3 py-2 rounded-lg border border-red-200">
        {{ errorMessage }}
      </div>
    </div>
  </div>
</template>

<script>
import { uiBusinessAdapter } from '../../adapters'
import { voiceActivityDetector } from '../../services/voice/voiceActivityDetector'
import { appConfig } from '../../config/appConfig'

export default {
  name: 'LiveDictation',
  props: {
    adapter: {
      type: Object,
      default: () => uiBusinessAdapter
    },
    panelHeight: {
      type: String,
      default: 'h-64'
    }
  },
  data() {
    return {
      completedSentences: [],
      currentPartial: '',
      lastSnapshotKey: '',
      isRecording: false,
      isInitializing: false,
      errorMessage: '',
      lastCommittedText: '',
      // –ü–æ—Ç–æ–∫ –∫—É—Å–æ—á–∫–æ–≤ –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∞
      completedChunks: [],
      // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ batch
      batchMode: true,
      batchMs: 10000,
      mediaStream: null,
      mediaRecorder: null,
      batchChunks: [],
      batchTimer: null,
      // VAD —Å–æ—Å—Ç–æ—è–Ω–∏–µ
      vadUnsubscribe: null,
      vadState: null,
      useVAD: appConfig.voice.vad?.enabled || false,
      // –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
      windowDurations: [1000, 3000, 5000, 10000],
      windowIndex: 0,
      windowStartTs: 0,
      pendingBuffer: ''
    }
  },
  computed: {
    diarizedMessages() {
      try {
        return this.adapter.getChatStore().getters.diarizedMessages() || []
      } catch (e) {
        return []
      }
    },
    hasDeepGramKey() {
      try {
        const apiKey = import.meta.env.VITE_DEEPGRAM_API_KEY || localStorage.getItem('deepgram_api_key')
        return apiKey && apiKey.length >= 10
      } catch (e) {
        return false
      }
    }
  },
  watch: {
    completedChunks() {
      this.$nextTick(() => this.scrollToBottom())
    },
    diarizedMessages: {
      handler() {
        if (!this.batchMode) this.rebuildTranscriptIncremental()
      },
      deep: true,
      immediate: true
    }
  },
  methods: {
    async toggleDictation() {
      if (this.isRecording) {
        await this.stopDictation()
      } else {
        await this.startDictation()
      }
    },
    async startDictation() {
      try {
        this.errorMessage = ''
        this.isInitializing = true

        if (this.batchMode) {
          await this.startBatchRecording()
          this.isRecording = true
          this.$nextTick(() => this.scrollToBottom())
          return
        }

        // Streaming –ø—É—Ç—å
        try {
          const stateGetter = this.adapter.getChatStore()?.getters?.diarizationState
          const state = typeof stateGetter === 'function' ? stateGetter() : null
          if (state?.isPaused && this.adapter?.resumeDiarization) {
            await this.adapter.resumeDiarization()
          } else if (this.adapter?.startDiarization) {
            await this.adapter.startDiarization()
          }
        } catch (e) {}
        await this.waitForDiarizationReady(2000)
        await this.adapter.executeAction('audioMixer.start')
        this.isRecording = true
        this.$nextTick(() => this.scrollToBottom())
      } catch (e) {
        this.errorMessage = '–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å –¥–∏–∫—Ç–æ–≤–∫—É: ' + (e?.message || e)
      } finally {
        this.isInitializing = false
      }
    },
    async stopDictation() {
      try {
        this.errorMessage = ''
        if (this.batchMode) {
          await this.stopBatchRecording()
          this.isRecording = false
          return
        }
        await this.adapter.executeAction('audioMixer.stop')
        try { if (this.adapter?.pauseDiarization) await this.adapter.pauseDiarization() } catch(e) {}
        this.isRecording = false
      } catch (e) {
        this.errorMessage = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –¥–∏–∫—Ç–æ–≤–∫–∏: ' + (e?.message || e)
      }
    },

    async startBatchRecording() {
      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } })
      const supported = [ 'audio/webm;codecs=opus', 'audio/webm', 'audio/mp4', 'audio/mp4;codecs=opus' ]
      let mimeType = 'audio/webm;codecs=opus'
      for (const t of supported) { if (MediaRecorder.isTypeSupported(t)) { mimeType = t; break } }
      this.mediaRecorder = new MediaRecorder(this.mediaStream, { mimeType })
      this.batchChunks = []
      
      // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ VAD –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
      if (this.useVAD) {
        try {
          const vadConfig = appConfig.voice.vad || {}
          voiceActivityDetector.updateConfig(vadConfig)
          await voiceActivityDetector.connect(this.mediaStream)
          
          this.vadUnsubscribe = voiceActivityDetector.onStateChange((state) => {
            this.vadState = state
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á –∫–æ–≥–¥–∞ VAD –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å
            if (state.shouldFlushBatch && this.mediaRecorder && this.mediaRecorder.state === 'recording') {
              console.log('üé§ [VAD] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á –ø–æ —Å–∏–≥–Ω–∞–ª—É VAD')
              this.mediaRecorder.stop()
            }
          })
          
          console.log('üé§ [LiveDictation] VAD –ø–æ–¥–∫–ª—é—á–µ–Ω –¥–ª—è —É–º–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –±–∞—Ç—á–µ–π')
        } catch (e) {
          console.warn('üé§ [LiveDictation] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å VAD, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–π–º–µ—Ä:', e)
          this.useVAD = false
        }
      }
      
      this.mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) this.batchChunks.push(e.data)
      }
      
      this.mediaRecorder.onstop = async () => {
        try {
          const blob = new Blob(this.batchChunks, { type: mimeType })
          console.log(`üé§ [LiveDictation] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á —Ä–∞–∑–º–µ—Ä–æ–º ${Math.round(blob.size/1024)}KB`)
          
          const { transcribeBlobWithDeepgram } = await import('../../services/voice/batchTranscriptionService')
          const result = await transcribeBlobWithDeepgram(blob)
          
          console.log(`üé§ [LiveDictation] –ü–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç: "${result?.transcript}", confidence=${result?.confidence}`)
          
          if (result?.transcript) {
            // –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ confidence
            this.completedChunks.push(result.transcript)
            this.completedChunks.push('\n')
            this.$emit('use-in-chat', result.transcript)
            console.log(`‚úÖ [LiveDictation] –î–æ–±–∞–≤–ª–µ–Ω —Ç–µ–∫—Å—Ç: "${result.transcript}" (confidence: ${result.confidence})`)
            this.$nextTick(() => this.scrollToBottom())
          } else {
            console.log(`‚ùå [LiveDictation] –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è`)
          }
        } catch (e) {
          console.error('üé§ [LiveDictation] –û—à–∏–±–∫–∞ –±–∞—Ç—á-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', e)
          this.errorMessage = '–û—à–∏–±–∫–∞ –±–∞—Ç—á-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: ' + (e?.message || e)
        } finally {
          this.batchChunks = []
          
          // –°–±—Ä–∞—Å—ã–≤–∞–µ–º VAD —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
          if (this.useVAD && voiceActivityDetector) {
            voiceActivityDetector.resetBatch()
          }
          
          if (this.isRecording) {
            this.mediaRecorder.start()
            
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –∫–∞–∫ fallback (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è)
            if (this.batchTimer) clearTimeout(this.batchTimer)
            const maxTime = this.useVAD ? (appConfig.voice.vad?.maxBatchDuration || 15000) : this.batchMs
            this.batchTimer = setTimeout(() => {
              try { 
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                  console.log('üé§ [LiveDictation] –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏')
                  this.mediaRecorder.stop() 
                }
              } catch (e) {}
            }, maxTime)
          }
        }
      }
      
      this.mediaRecorder.start()
      console.log(`üé§ [LiveDictation] –ù–∞—á–∞—Ç–∞ –∑–∞–ø–∏—Å—å –±–∞—Ç—á–∞, VAD: ${this.useVAD ? '–≤–∫–ª—é—á–µ–Ω (–ø–∞—É–∑–∞ 300–º—Å)' : '–≤—ã–∫–ª—é—á–µ–Ω'}`)
      
      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º fallback —Ç–∞–π–º–µ—Ä
      if (this.batchTimer) clearTimeout(this.batchTimer)
      const maxTime = this.useVAD ? (appConfig.voice.vad?.maxBatchDuration || 15000) : this.batchMs
      this.batchTimer = setTimeout(() => {
        try { 
          if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
            console.log('üé§ [LiveDictation] –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ –ø–æ —Ç–∞–π–º–µ—Ä—É')
            this.mediaRecorder.stop() 
          }
        } catch (e) {}
      }, maxTime)
      
      this.isRecording = true
    },

    async stopBatchRecording() {
      try {
        // –û—Ç–∫–ª—é—á–∞–µ–º VAD
        if (this.vadUnsubscribe) {
          this.vadUnsubscribe()
          this.vadUnsubscribe = null
        }
        if (this.useVAD) {
          voiceActivityDetector.disconnect()
        }
        
        if (this.batchTimer) {
          clearTimeout(this.batchTimer)
          this.batchTimer = null
        }
        if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
          this.mediaRecorder.stop()
        }
      } catch (e) {}
      try {
        if (this.mediaStream) {
          this.mediaStream.getTracks().forEach(t => t.stop())
        }
      } catch (e) {}
      this.mediaRecorder = null
      this.mediaStream = null
      this.batchChunks = []
      this.vadState = null
    },

    async waitForDiarizationReady(timeoutMs) {
      const start = Date.now()
      while (Date.now() - start < timeoutMs) {
        try {
          const getter = this.adapter.getChatStore()?.getters?.diarizationState
          const st = typeof getter === 'function' ? getter() : null
          if (st?.isActive || st?.isConnecting) return
        } catch (e) {}
        await new Promise(r => setTimeout(r, 100))
      }
    },

    rebuildTranscriptIncremental() {
      if (!this.diarizedMessages || this.diarizedMessages.length === 0) {
        this.currentPartial = ''
        return
      }
      const last = this.diarizedMessages[this.diarizedMessages.length - 1]
      const text = (last && (last.text || last.content) || '').trim()
      if (!text) return

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–∫–Ω–∞
      if (!this.windowStartTs) {
        this.windowStartTs = Date.now()
        this.windowIndex = 0
        this.pendingBuffer = ''
      }

      // –î–æ–±–∞–≤–ª—è–µ–º –ª—é–±—ã–µ –Ω–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –±—É—Ñ–µ—Ä
      const delta = this.diffNewText(this.lastCommittedText, text)
      if (delta) {
        this.pendingBuffer += (this.pendingBuffer && !this.pendingBuffer.endsWith(' ') ? ' ' : '') + delta
        this.lastCommittedText = text
      }

      const elapsed = Date.now() - this.windowStartTs
      const currentWindow = this.windowDurations[Math.min(this.windowIndex, this.windowDurations.length - 1)]

      // –ö—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ–ª–∞—à–∞: –∏—Å—Ç–µ–∫–ª–æ –æ–∫–Ω–æ –∏–ª–∏ –µ—Å—Ç—å –∑–∞–≤–µ—Ä—à–∞—é—â–∞—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è
      const hasPunctuation = /[.!?]$/.test(text)
      if (this.pendingBuffer && (elapsed >= currentWindow || hasPunctuation)) {
        this.completedChunks.push(this.pendingBuffer.trim())
        this.completedChunks.push('\n')
        this.$emit('use-in-chat', this.pendingBuffer.trim())
        this.pendingBuffer = ''
        this.windowStartTs = Date.now()
        if (this.windowIndex < this.windowDurations.length - 1) {
          this.windowIndex += 1
        }
        this.$nextTick(() => this.scrollToBottom())
      }

      // –°–µ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
      this.currentPartial = ''
    },

    diffNewText(prev, current) {
      if (!prev) return current
      if (current.startsWith(prev)) return current.slice(prev.length).trim()
      return current
    },

    scrollToBottom() {
      try {
        const el = this.$refs.scrollArea
        if (el && el.scrollHeight !== undefined) {
          el.scrollTop = el.scrollHeight
        }
      } catch (e) {}
    }
  }
}
</script>

<style scoped>
.prose p { margin: 0; }
</style>
